{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Satellite-based monitoring of dry and wet conditions using Standardized Precipitation Index (SPI)","text":"<p>The Standardized Precipitation Index (SPI) analysis is following the training conducted in 28 Jan 2020 by NASA ARSET on Application of GPM IMERG Reanalysis for Assessing Extreme Dry and Wet Periods. https://appliedsciences.nasa.gov/join-mission/training/english/arset-applications-gpm-imerg-reanalysis-assessing-extreme-dry-and-wet</p> <p>The training session from NASA ARSET provided information on how to access and download IMERG data, and use it to calculate SPI on defined time scales. Many participant experience several problems and try to raise some question to the developer of <code>climate-indices</code> python package in their Github page and some also ask in StackExchange. I also experience several problem during the training and try to documented the solution by modified some step on their guideline.</p> <p>In this site, I would like to re-share on how to calculate SPI using NASA ARSET approach and provide alternative way using different data and format. This how-to guideline will use latest version of Climate Indices in Python software. While NASA ARSET training still used the official release version from U.S. Drought Portal</p> <p>On How-to? section, you will find step-by-step guideline to calculate SPI, and can try different (data source and format) approach below:</p> <ul> <li>SPI based on IMERG data in netCDF format (following NASA ARSET training but adjusted in some step)</li> <li>SPI based on CHIRPS data GeoTIFF  format</li> <li>SPI based on CHIRPS data in netCDF format</li> </ul> <p></p>"},{"location":"#notes","title":"Notes","text":"<ul> <li>This step-by-step guide was tested using Macbook Pro, 2.9 GHz 6-Core Intel Core i9, 32 GB 2400 MHz DDR4, running on macOS Catalina 10.15.7</li> <li> <p>And a Windows Server 2019 running in Parallels Desktop for Mac, with Windows Subsystem for Linux (WSL) installed.</p> <p>Info</p> <p>I will use a standard WSL 2 for Windows 10 as most of Windows user are using Windows 10 for their works. </p> </li> </ul>"},{"location":"background/","title":"Background on the SPI","text":"<p>The Standardized Precipitation Index (SPI) is a drought index first developed by T. B. McKee, N.J. Doesken, and J. Kleist and in 1993 (McKee et al. 1993). The SPI is used for estimating wet or dry condition based on precipitation variable. This wet or dry condition can be monitored by the SPI on a variety of time scales from subseasonal to interannual scales. The SPI is expressed as standard deviations that the observed precipitation would deviate from the long-term mean, for a normal distribution and fitted probability distribution for the actual precipitation record. Since precipitation is not normally distributed, a transformation is first applied, followed by fitting to a normal distribution.</p>"},{"location":"background/#calculation","title":"Calculation","text":"<p>The SPI calculation is based on the long-term precipitation record for a particular location and long-term period (longer than 30 years is desirable). The calculation method is comprised of a transformation of one frequency distribution (e.g., gamma) to another frequency distribution (normal, or Gaussian). The first step to calculate SPI is to adequately choose a particular probability distribution (e.g., gamma distribution, incomplete beta distribution (McKee et al. (1993, 1995)), and Pearson III distribution (Guttman (1998, 1999))) that reliably fits the long-term precipitation time series and conduct fitting to that distribution. Gamma distribution has been widely used, as the gamma distribution has been understood as the reliable fit to the precipitation distribution. The fitting can be achieved through the maximum likelihood estimation of the gamma distribution parameters. The percentile value from this probability distribution is then transformed to the corresponding value in the new probability distribution. As a result, the probability that the rainfall is less than or equal to any rainfall amount will be the same as the probability that the new variate is less than or equal to the corresponding value of that rainfall amount. The normal distribution is usually used for this another transformation so that the mean and standard deviation of the SPI for a certain station and long-term period is zero and one, respectively (Edwards and McKee 1997). Positive SPI values indicate wet condition greater than median precipitation, whereas negative values the dry condition less than median precipitation. More detailed description of the steps required to calculate the SPI is provided in Lloyd-Hughes and Saunders (2002).</p>"},{"location":"background/#interpretation","title":"Interpretation","text":"<p>Since the SPI values are obtained from the standard normal distribution, the unit of the SPI can be \u201cstandard deviations\u201d. The following table summarizes the cumulative probabilities for various SPI values and possible interpretation of wet (or dry) conditions using the resulting SPI values.</p> SPI Cumulative Probability Interpretation -3.0 0.0014 Extremely dry -2.5 0.0062 Extremely dry -2.0 0.0228 Extremely dry (SPI &lt; -2.0) -1.5 0.0668 Severly dry (-2.0 &lt; SPI &lt; -1.5) -1.0 0.1587 Moderately dry (-1.5 &lt; SPI &lt; -1.0) -0.5 0.3085 Near normal 0.0 0.5000 Near normal 0.5 0.6915 Near normal 1.0 0.8413 Moderately wet (1.0 &lt; SPI &lt; 1.5) 1.5 0.9332 Severly wet (1.5 &lt; SPI &lt; 2.0) 2.0 0.9772 Extremely wet (2.0 &lt; SPI &lt;) 2.5 0.9938 Extremely wet 3.0 0.9986 Extremely wet <p>The SPI maps can be interpreted at various time scales. This in turn indicates that the SPI is useful in both short-term and long-term applications. These time scales reflect the impact of drought on the availability of the different water resources. For instance, soil moisture conditions respond to precipitation anomalies on a relatively short scale. Groundwater, streamflow, and reservoir storage reflect the longer-term precipitation anomalies. For these reasons, SPI was originally calculated for 3\u2013, 6\u2013,12\u2013, 24\u2013, and 48\u2013month time scales (McKee et al. (1993)). A separate SPI value can be calculated for a selection of time scales, covering the last months (e.g., 3, 6, 12, 24, and 48 months), and ending on the last day of the latest month.</p> <p>Source: https://gmao.gsfc.nasa.gov/research/subseasonal/atlas/SPI-html/SPI-description.html</p>"},{"location":"background/#strengths-and-limitations","title":"Strengths and Limitations","text":"<ul> <li>Used for estimating meteorological conditions based on precipitation alone.</li> <li>Wet or dry conditions can be monitored on a variety of time scales from sub seasonal to interannual</li> <li>Can be compared across regions with markedly difference climates</li> <li>Does not consider the intensity of precipitation and its potential impacts on runoff, streamflow, and water availability</li> <li>Expressed as the number of standard deviations from the long term mean, for a normally distributed random variable, and fitted probability distribution for the actual precipitation record</li> <li>SPI values &lt; 1 indicate a condition of drought, the more negative the value the more severe the drought condition. SPI values &gt; +1 indicate wetter conditions compared to a climatology</li> </ul>"},{"location":"background/#example","title":"Example","text":"<p>Expressed as the number of standard deviations from the long-term mean, for a normally distributed random variable, and fitted probability distribution for the actual precipitation record</p> <p>SPI values &lt; -1 indicate a condition of drought, the more negative the value the more severe the drought condition. SPI values &gt; +1 indicate wetter conditions compared to a climatology</p> <p>https://drought.unl.edu/droughtmonitoring/SPI.aspx</p> <ul> <li> <p>SPI 1-month</p> <p>Similar to a map displaying the percent of normal precipitation for a month. Reflects relatively short term conditions. Its application can be related closely with short term soil moisture and crop stress.</p> <p></p> </li> <li> <p>3 month</p> <p>Provides a comparison of the precipitation over a specific 3 month period with the precipitation totals from the same 3 month period for all the years included in the historical record. Reflects short and medium term moisture conditions and provides a seasonal estimation of precipitation.</p> <p></p> </li> <li> <p>6 month</p> <p>Compares the precipitation for that period with the same 6 month period over the historical record. A 6 month SPI can be very effective in showing the precipitation over distinct seasons and may be associated with anomalous streamflow and reservoir levels.</p> <p></p> </li> <li> <p>9 month</p> <p>Provides an indication of precipitation patterns over a medium time scale. SPI values below 1.5 for these time scales are usually a good indication that significant impacts are occurring in agriculture and may be showing up in other sectors as well.</p> <p></p> </li> <li> <p>12 month</p> <p>Reflects long term precipitation patterns. Longer SPIs tend toward zero unless a specific trend is taking place. SPIs of these time scales are probably tied to streamflow, reservoir levels, and even groundwater levels at the longer time scales. In some locations of the country, the 12 month SPI is most closely related with the Palmer Index, and the two indices should reflect similar conditions.</p> <p></p> </li> </ul> <p></p> <p>SPI labels and their relationship to the normal curve. The intensity implied by each label corresponds to the degree of removal from mean conditions (i.e., SPI=0). The percentages printed within the regions bounded by the dashed lines indicate the probability for SPI values to fall within that region only. (Source: J. Keyantash)</p>"},{"location":"chirpsnc/","title":"3.3. CHIRPS monthly in netCDF format","text":"<p>This section will explain on how to download CHIRPS monthly data in netCDF format and prepare it as input for SPI calculation.</p> <ul> <li>Make sure you still inside conda <code>gis</code> environment</li> </ul>"},{"location":"chirpsnc/#download-chirps-data","title":"Download CHIRPS data","text":"<ul> <li>Navigate to <code>Downloads/CHIRPS/netCDF/Original</code> folder in the working directory. Download using <code>wget</code> all CHIRPS dekad data in netCDF format from Jan 1981 to Apr 2021 (this is lot of data +- 6.4GB, please make sure you have bandwidth and unlimited data package). Paste and Enter below script in your Terminal.</li> </ul> <pre><code>wget -c https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_monthly/netcdf/chirps-v2.0.monthly.nc\n</code></pre> <ul> <li>As an alternative, you can download via ftp client like FileZilla. Below is exampe using ftp client Transmit for Mac.</li> </ul>"},{"location":"chirpsnc/#clip-data-using-a-bounding-box-based-on-area-of-interest","title":"Clip data using a bounding box based on area of interest","text":"<p>I am providing example on how to use CDO and NCO to do some data extraction process, you can choose which one is suits you. In my opinion, NCO is faster than CDO, and NCO produce smaller size of output.</p> <ul> <li>Crop your area of interest using bounding box.      Example: Java bounding box with format <code>lon1</code>,<code>lon2</code>,<code>lat1</code>,<code>lat2</code> is <code>105.05</code>,<code>116.25</code>,<code>-8.8</code>,<code>-5.05</code></li> </ul> <p>Paste and Enter below code in your Terminal.</p> <p>CDO script:</p> <pre><code>cdo sellonlatbox,105.05,116.25,-8.8,-5.05 chirps-v2.0.monthly.nc ../Clipped/java_chirps-v2.0.monthly.nc\n</code></pre> <p></p> <p>NCO script</p> <pre><code>ncks -d latitude,-8.8,-5.05 -d longitude,105.05,116.25 chirps-v2.0.monthly.nc -O ../Clipped/java_chirps-v2.0.monthly.nc\n</code></pre> <p></p> <ul> <li>Let's read header contents of above result. Type and execute below code:</li> </ul> <pre><code>ncdump -h java_chirps-v2.0.monthly.nc\n</code></pre> <p>You will get information (dimension, variables and global attribute) about the data.</p> <p></p>"},{"location":"chirpsnc/#edit-variable-and-attribute","title":"Edit variable and attribute","text":"<p>As explain in Input specification, we can say from above picture there are few variable and attribute that need editing. Let's do it one-by-one.</p> <ul> <li>Navigate to <code>Downloads/CHIRPS/netCDF/Clipped</code> folder in the working directory.</li> </ul> <p>Variable</p> <ul> <li>Edit variable name for <code>longitude</code> to <code>lon</code>, and <code>latitude</code> to <code>lat</code></li> </ul> <p>Paste and Enter line-by-line CDO script below in Terminal.</p> <pre><code>cdo chname,longitude,lon java_chirps-v2.0.monthly.nc java_chirps-v2.0.monthly_1.nc\ncdo chname,latitude,lat java_chirps-v2.0.monthly_1.nc java_chirps-v2.0.monthly_2.nc\n</code></pre> <p></p> <p>Alternative, using NCO script is below</p> <pre><code>ncrename -d longitude,lon -d latitude,lat -v longitude,lon -v latitude,lat java_chirps-v2.0.monthly.nc -O java_chirps-v2.0.monthly_2.nc\n</code></pre> <p></p> <ul> <li>Let's read header contents of above result. Type and execute below code:</li> </ul> <pre><code>ncdump -h java_chirps-v2.0.monthly_2.nc\n</code></pre> <p>Result from CDO</p> <p></p> <p>Result from NCO</p> <p></p> <p>Attribute</p> <ul> <li>Edit precipitation unit from <code>mm/month</code> to <code>mm</code></li> </ul> <p>Paste and Enter line-by-line CDO script below in Terminal.</p> <pre><code>cdo -setattribute,precip@units=\"mm\" java_chirps-v2.0.monthly_2.nc java_chirps-v2.0.monthly_3.nc\n</code></pre> <p></p> <p>Alternative, using NCO script is below</p> <pre><code>ncatted -a units,precip,modify,c,'mm' java_chirps-v2.0.monthly_2.nc java_chirps-v2.0.monthly_3.nc\n</code></pre> <p></p> <ul> <li>Let's read header contents of above result. Type and execute below code:</li> </ul> <pre><code>ncdump -h java_chirps-v2.0.monthly_3.nc\n</code></pre> <p>Result from CDO</p> <p></p> <p>Result from NCO</p> <p></p> <p>And the units already in <code>mm</code></p> <p>Once this has completed, the dataset can be used as input to this package for computing SPI. From above picture, some of the precipitation attribute are still wrong: <code>DimensionNames</code> and <code>Units</code>. I can leave it as is, SPI code will only read <code>units</code> and variables <code>precip(time,lat,lon)</code></p> <p>As the input data preparation is completed, move the file <code>java_chirps-v2.0.monthly_3.nc</code> to main folder <code>Input_nc</code> and rename into <code>java_cli_imerg_1months_1981_2020.nc</code></p> <pre><code>mv java_chirps-v2.0.monthly_3.nc ../../../../Input_nc/java_cli_imerg_1months_2000_2020.nc\n</code></pre> <p>Make sure the file <code>java_cli_imerg_1months_1981_2020.nc</code> is available at <code>Input_nc</code> folder</p>"},{"location":"chirpstif/","title":"3.2. CHIRPS monthly in GeoTIFF format","text":"<p>This section will explain on how to download CHIRPS monthly data in GeoTIFF format and prepare it as input for SPI calculation.</p> <ul> <li>Make sure you still inside conda <code>gis</code> environment</li> </ul>"},{"location":"chirpstif/#download-chirps-data","title":"Download CHIRPS data","text":"<ul> <li>Navigate to <code>Downloads/CHIRPS/GeoTIFF</code> folder in the working directory. Download using <code>wget</code> all CHIRPS monthly data in GeoTIFF format from Jan 1981 to Dec 2020 (this is lot of data +-7GB zipped files, and become 27GB after extraction, please make sure you have bandwidth and unlimited data package). Paste and Enter below script in your Terminal.</li> </ul> <pre><code>export URL='https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_monthly/tifs/'; curl \"$URL\" | grep -E 'a href=' | perl -pe 's|.*href=\"(.*?)\".*|\\1|' | { while read -r f; do wget \"$URL\"/\"$f\"; done }\n</code></pre> <ul> <li>Gunzip all the downloaded files</li> </ul> <pre><code>gunzip *.gz\n</code></pre>"},{"location":"chirpstif/#clip-data-using-a-shapefile-based-on-area-of-interest","title":"Clip data using a shapefile based on area of interest","text":"<ul> <li>Download the Java boundary shapefile https://github.com/bennyistanto/spi/blob/master/example/Data/Subset/java_bnd_chirps_subset.zip. And save it in Subset directory then unzip it.</li> </ul> <p>Info</p> <p>You can use your own boundary in shapefile and use it to clip the rainfall raster data based on your preferred area of interest.</p> <ul> <li>Still in your <code>GeoTIFF</code> directory, Clip your area of interest using Java boundary and save it to <code>Input_TIF</code> directory. I will use <code>gdalwarp</code> command from GDAL to clip all GeoTIFF files in a folder.</li> </ul> <pre><code>for i in `find *.tif`; do gdalwarp --config GDALWARP_IGNORE_BAD_CUTLINE YES -srcnodata NoData -dstnodata -9999 -cutline ../../../Subset/java_bnd_chirps_subset.shp -crop_to_cutline $i ../../../Input_TIF/java_$i; done\n</code></pre> <p></p> <p>If you have limited data connection or lazy to download +-7GB and process +-27GB data, you can get pre-processed clipped data for Java covering Jan 1981 to Dec 2020, with file size +-6.8MB. Link: https://github.com/bennyistanto/spi/blob/master/example/Data/Input_TIF</p>"},{"location":"chirpstif/#convert-geotiffs-to-single-netcdf","title":"Convert GeoTIFFs to single netCDF","text":"<ul> <li> <p>Download python script/notebook that I use to convert GeoTIFF in a folder to single netCDF, save it to <code>Script</code> folder.</p> <ul> <li>Jupyter notebook</li> <li>Python script</li> </ul> </li> </ul> <p>Below is the script</p> <pre><code>#!/usr/bin/env python\n\"\"\"\n-------------------------------------------------------------------------------------------------------------\nConvert CHIRPS GeoTIFF in a folder to single NetCDF file with time dimension enabled that is CF-Compliant\nhttp://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html\nBased on Rich Signell's answer on StackExchange: https://gis.stackexchange.com/a/70487\nThis script was tested using CHIRPS dekad data. Adjustment is needed if using other timesteps data for CHIRPS\nNCO (http://nco.sourceforge.net) must be installed before using this script\nModified by\nBenny Istanto, BIGC, benny@istan.to\n-------------------------------------------------------------------------------------------------------------\n\"\"\"\n# Case Java island, Indonesia - 105.05,116,25,-8.80,-5.05\n#\n# Original data in GeoTIFF format downloaded from https://data.chc.ucsb.edu/products/CHIRPS-2.0/global_monthly/tifs/\n# Then clipped using Java boundary (http://on.istan.to/365PSyH) via gdalwarp\n# for i in `find *.tif`; do gdalwarp --config GDALWARP_IGNORE_BAD_CUTLINE YES -srcnodata NoData -dstnodata -9999 -cutline java_bnd_chirps_subset.shp -crop_to_cutline $i java_$i; done\n# \n# Clipped GeoTIFF file for Java (https://on.istan.to/3iLu68v)\nimport numpy as np\nimport datetime as dt\nimport os\nimport gdal\nimport netCDF4\nimport re\nds = gdal.Open('/path/to/directory/java_chirps-v2.0.1981.01.tif') # Data location\na = ds.ReadAsArray()\nnlat,nlon = np.shape(a)\nb = ds.GetGeoTransform() #bbox, interval\nlon = np.arange(nlon)*b[1] + b[0] + (b[1]/2)  # add half the x pixel size to the lon\nlat = np.arange(nlat)*b[5] + b[3] + (b[5]/2)  # add half the y pixel size to the lat\nlat = np.flipud(lat)  # flip the latitudes\nbasedate = dt.datetime(1980,1,1,0,0,0)\n# Create NetCDF file\nnco = netCDF4.Dataset('java_cli_chirps_1months_1981_2020.nc','w',clobber=True) # Output name\n# Create dimensions, variables and attributes:\nnco.createDimension('lon',nlon)\nnco.createDimension('lat',nlat)\nnco.createDimension('time',None)\ntimeo = nco.createVariable('time','f4',('time'))\ntimeo.units = 'days since 1980-1-1 00:00:00'\ntimeo.standard_name = 'time'\ntimeo.calendar = 'gregorian'\ntimeo.axis = 'T'\nlono = nco.createVariable('lon','f4',('lon'))\nlono.units = 'degrees_east'\nlono.standard_name = 'longitude'\nlono.long_name = 'longitude'\nlono.axis = 'X'\nlato = nco.createVariable('lat','f4',('lat'))\nlato.units = 'degrees_north'\nlato.standard_name = 'latitude'\nlato.long_name = 'latitude'\nlato.axis = 'Y'\n# Create container variable for CRS: lon/lat WGS84 datum\ncrso = nco.createVariable('crs','i4')\ncrso.long_name = 'Lon/Lat Coords in WGS84'\ncrso.grid_mapping_name='latitude_longitude'\ncrso.longitude_of_prime_meridian = 0.0\ncrso.semi_major_axis = 6378137.0\ncrso.inverse_flattening = 298.257223563\n# Create float variable for precipitation data, with chunking\npcpo = nco.createVariable('precip', 'f4',  ('time', 'lat', 'lon'),zlib=True,fill_value=-9999.)\npcpo.units = 'mm'\npcpo.standard_name = 'convective precipitation rate'\npcpo.long_name = 'Climate Hazards group InfraRed Precipitation with Stations'\npcpo.time_step = 'dekad'\npcpo.missing_value = -9999.\npcpo.geospatial_lat_min = -8.8\npcpo.geospatial_lat_max = -5.05\npcpo.geospatial_lon_min = 105.05\npcpo.geospatial_lon_max = 116.25\npcpo.grid_mapping = 'crs'\npcpo.set_auto_maskandscale(False)\n# Additional attributes\nnco.Conventions='CF-1.6'\nnco.title = \"CHIRPS v2.0\"\nnco.history = \"created by Climate Hazards Group. University of California at Santa Barbara\"\nnco.version = \"Version 2.0\"\nnco.comments = \"time variable denotes the first day of the given dekad.\"\nnco.website = \"https://www.chc.ucsb.edu/data/chirps\"\nnco.date_created = \"2021-01-25\"\nnco.creator_name = \"Benny Istanto\"\nnco.creator_email = \"benny@istan.to\"\nnco.institution = \"Benny Istanto Geospatial Consulting\"\nnco.note = \"The data is developed to support regular updating procedure for SPI analysis (https://github.com/bennyistanto/spi). This activities will support me to assess extreme dry and wet periods as part of my Climate Social Responsibility\"\n# Write lon,lat\nlono[:]=lon\nlato[:]=lat\npat = re.compile('java_chirps-v2.0.[0-9]{4}\\.[0-9]{2}')\nitime=0\n# Step through data, writing time and data to NetCDF\nfor root, dirs, files in os.walk('/path/to/directory/'):\ndirs.sort()\nfiles.sort()\nfor f in files:\nif re.match(pat,f):\n# read the time values by parsing the filename\nyear=int(f[17:21])\nmon=int(f[22:24])\ndate=dt.datetime(year,mon,1,0,0,0)\nprint(date)\ndtime=(date-basedate).total_seconds()/86400.\ntimeo[itime]=dtime\n# precipitation\npcp_path = os.path.join(root,f)\nprint(pcp_path)\npcp=gdal.Open(pcp_path)\na=pcp.ReadAsArray()  #data\npcpo[itime,:,:]=np.flipud(a)  # flip the data in y-direction\nitime=itime+1\nnco.close()\n</code></pre> <p>You MUST adjust the folder location (replace <code>/path/to/directory/</code> with yours, example: <code>/Users/bennyistanto/Temp/CHIRPS/SPI/Input_TIF/java_cli_chirps-v2.0.1981.01.1.tif</code>) in line 31 and 114.</p> <p>Warning</p> <p>If you are using other data source (I assume all the data in WGS84), you need to adjust few code in:</p> <p>Line 31: folder location Line 40: start of the date Line 44: output name Line 53: date attribute Line 85-88: bounding box Line 110: output filename structure Line 114: folder location Line 120-122: date character location in a filename</p> <ul> <li> <p>After everything is set, then you can execute the translation process (choose one or you can try both for learning)</p> <ul> <li>Using Python in Terminal, navigate to your <code>Script</code> directory, type <code>python tiff2nc.py</code></li> </ul> <p></p> <p>Wait for a few moments, you will get the output <code>java_cli_chirps_1months_1981_2020.nc</code>. You will find this file inside <code>Input_TIF</code> folder. Move it to <code>Input_nc</code> folder.</p> <ul> <li>Using Jupyter, make sure you still inside conda <code>gis</code> environment.</li> </ul> <p>Access this <code>*.ipynb</code> file inside <code>Script</code> folder. Move it to <code>Input_TIF</code> folder. </p> <p>Navigate your Terminal to <code>Input_TIF</code> then type <code>jupyter notebook</code></p> <p></p> <p>Navigate to your notebook directory (where you put <code>*.ipynb</code> file), run Cell by Cell until completed. Wait for a few moments, you will get the output <code>java_cli_chirps_1months_1981_2020.nc</code>. </p> <p></p> </li> <li> <p>As the input data preparation is completed, move the file <code>java_cli_chirps_1months_1981_2020.nc</code> to main folder <code>Input_nc</code></p> </li> </ul> <pre><code>mv java_cli_chirps_1months_1981_2020.nc ../../../Input_nc/java_cli_imerg_1months_1981_2020.nc\n</code></pre> <p></p> <p>Make sure the file <code>java_cli_chirps_1months_1981_2020.nc</code> is available at <code>Input_nc</code> folder</p> <p></p> <ul> <li>You also can get this data: <code>java_cli_chirps_1months_1981_2020.nc</code> via this link https://github.com/bennyistanto/spi/blob/master/example/Data/Input_nc/java_cli_chirps_1months_1981_2020.nc</li> </ul>"},{"location":"conversion/","title":"7. Convert the result to GeoTIFF","text":"<p>Warning</p> <p>Below guideline using CHIRPS data as example. If you are using IMERG, just replace text CHIRPS in the script or filename below with IMERG.</p> <p>I need CDO to do a conversion of the result into GeoTIFF format, and CDO required the variable should be in <code>time</code>, <code>lat</code>, <code>lon</code>, while the output from SPI: <code>java_xxxxx_spi_xxxxx_x_month.nc</code> in <code>lat</code>, <code>lon</code>, <code>time</code>, you can check this via <code>ncdump -h java_CHIRPS_spi_gamma_3_month.nc</code></p> <ul> <li>Deactivate an active environment <code>climate_indices</code> then activate environment <code>gis</code> to start working on output conversion using CDO and GDAL.</li> </ul> <pre><code>conda deactivate &amp;&amp; conda activate gis\n</code></pre> <ul> <li> <p>Navigate your Terminal to folder <code>Output_nc</code></p> </li> <li> <p>Let's re-order the variables into <code>time</code>,<code>lat</code>,<code>lon</code> using <code>ncpdq</code> command from NCO and save the result to folder <code>Output_TEMP</code></p> </li> </ul> <pre><code>ncpdq -a time,lat,lon java_CHIRPS_spi_gamma_3_month.nc ../Output_TEMP/java_CHIRPS_spi_gamma_3_month_rev.nc\n</code></pre> <ul> <li> <p>Navigate your Terminal to folder <code>Output_TEMP</code></p> </li> <li> <p>Check result and metadata to make sure everything is correct.</p> </li> </ul> <pre><code>ncdump -h java_CHIRPS_spi_gamma_3_month_rev.nc\n</code></pre> <ul> <li> <p>Then convert all SPI value into GeoTIFF with time dimension information as the filename using CDO and GDAL.</p> </li> <li> <p>Navigate your Terminal to folder <code>Output_TEMP</code>, execute below script and save the result to folder <code>Output_TIF</code></p> </li> </ul> <pre><code>for t in `cdo showdate java_CHIRPS_spi_gamma_3_month_rev.nc`; do\nformatted_date=$(date -d $t +%Y%m%d)\ncdo seldate,$t java_CHIRPS_spi_gamma_3_month_rev.nc dummy.nc     gdal_translate -of GTiff -a_ullr 105.05 -5.05 116.25 -8.8 -a_srs EPSG:4326 -co COMPRESS=LZW -co PREDICTOR=1 dummy.nc ../Output_TIF/java_cli_chirps_spi3_${formatted_date}.tif\ndone\n</code></pre> <p>Note</p> <p>If you are using IMERG or other data, or different area of interest, please make sure check the bounding box of the data <code>&lt;ulx&gt; &lt;uly&gt; &lt;lrx&gt; &lt;lry&gt;</code>. This <code>-a_ullr</code> assigns georeferenced bounds to the output file, ignoring what would have been derived from the source file.</p> <p>FINISH</p> <p>Congrats, now you are able to calculate SPI based on monthly rainfall in netCDF or GeoTIFF format.</p>"},{"location":"directory/","title":"0. Working Directory","text":"<p>For this tutorial, I am working on these folder <code>/Users/bennyistanto/Temp/xxx/SPI/Java</code> (applied to Mac/Linux machine) or <code>Z:/Temp/xxx/SPI/Java</code> (applied to Windows machine) directory. I have some folder inside this directory:</p> <ol> <li> <p><code>Downloads</code></p> <ol> <li> <p><code>IMERG</code></p> <ol> <li><code>IMERG_mmhr</code></li> <li><code>IMERG_mmmonth</code></li> <li><code>IMERG_originalfiles</code></li> </ol> </li> <li> <p><code>CHIRPS</code></p> <ol> <li><code>netCDF</code></li> <li><code>GeoTIFF</code></li> </ol> </li> </ol> <p>Place to put downloaded IMERG or CHIRPS data</p> </li> <li> <p><code>Fitting</code></p> <p>Place to put fitting parameters output from the calculation</p> </li> <li> <p><code>Input_nc</code></p> <p>Place to put netCDF data that will use as an input </p> </li> <li> <p><code>Input_TIF</code></p> <p>Place to put GeoTIFF file that will use to convert to single netCDF with time dimension enabled</p> </li> <li> <p><code>Output_nc</code></p> <p>Output folder for SPI calculation</p> </li> <li> <p><code>Output_TEMP</code></p> <p>Temporary for nc files from CDO arrange dimension process</p> </li> <li> <p><code>Output_TIF</code></p> <p>Final output of SPI, generate by CDO and GDAL</p> </li> <li> <p><code>Script</code></p> <p>Python script location to convert bunch of GeoTIFF file to single netCDF</p> </li> <li> <p><code>Subset</code></p> <p>Place to put shapefile for clipping area of interest</p> </li> </ol> <p>Feel free to use your own preferences for this setting/folder arrangements.</p> <p>Notes:</p> <p><code>xxx</code> = <code>IMERG</code> or <code>CHIRPS</code> (depend on the data used in tutorial)</p>"},{"location":"imergnc/","title":"3.1. IMERG monthly in netCDF format","text":"<p>Following the guideline from NASA ARSET, this section will explain on how to download IMERG monthly data in netCDF format and prepare it as input for SPI calculation.</p>"},{"location":"imergnc/#download-monthly-imerg-data-from-ges-disc","title":"Download monthly IMERG data from GES DISC","text":"<ul> <li> <p>Using a web browser, go to NASA Goddard Earth Sciences (GES) Data and Information Services Center (DISC): https://disc.gsfc.nasa.gov/</p> </li> <li> <p>Type \u201cIMERG\u201d in the search bar and click on the search</p> </li> <li> <p>Select IMERG Version 6 Level 3 data at \u201cmonthly\u201d temporal resolution and click on the \u201cSubset/Get Data\u201d icon</p> <p></p> </li> <li> <p>Current latest data is  up to Apr 2021, but for this guideline I will download for period Jun 2000 - Dec 2021</p> </li> <li> <p>Under Spatial Subset enter <code>105.05, -8.8, 116.25, -5.05</code> This spatial subset is for Java island, Indonesia</p> </li> <li> <p>Under Variables select only <code>precipitation</code></p> </li> <li> <p>Leave the default parameters under Grid</p> </li> <li> <p>Under File Format select \"netCDF\"</p> </li> <li> <p>Click Get Data</p> <p></p> </li> <li> <p>Data links windows will popup and you may click \"Download links list\"</p> <p></p> </li> <li> <p>You will get a txt file with similar filename like this one <code>subset_GPM_3IMERGM_06_20210707_044656.txt</code></p> </li> <li> <p>Move this file into your working directory (in this case I have folder <code>/Download/IMERG/IMERG_originalfiles</code> to save the txt file)</p> </li> <li> <p>Navigate your terminal to folder <code>/Downloads/IMERG/IMERG_originalfiles</code> and type this code to download the data:</p> </li> </ul> <pre><code>wget -c -i subset_GPM_3IMERGM_06_20200703_065511.txt`\n</code></pre> <p></p> <p>If you are lazy to follow the process of downloading data, for convenience these data are made available on via this link: https://github.com/bennyistanto/spi/blob/master/example/Data/Downloads/IMERG/IMERG_originalfiles.zip</p> <p>Once downloaded, unzip <code>IMERG_originalfiles.zip</code></p>"},{"location":"imergnc/#rename-all-the-data-into-friendly-filename","title":"Rename all the data into friendly filename","text":"<ul> <li> <p>If you check the data in folder <code>IMERG_originalfiles</code>, you will find the data with filename something like <code>HTTP_services.cgi?FILENAME=%2Fdata%2FGPM_L3%2FGPM_3IMERGM.06%2F2000%2F3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5&amp;FORMAT=bmM0Lw&amp;BBOX=-8.8,105.05,-5.05,116.25&amp;LABEL=3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5.nc4</code></p> <p></p> </li> <li> <p>I need to rename it all the file into friendly filename like this <code>3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5.nc4</code></p> </li> <li> <p>If you follow the download process, you may create a duplicate for contents in <code>IMERG_originalfiles</code> to <code>IMERG_mmhr</code> (just in case something happen to your downloaded files). But if you are not follow the download process but downloaded <code>IMERG_originalfiles.zip</code> folder, you are good.</p> </li> <li> <p>I will use regular expression and remove the first <code>178</code> characters in the filename (I will remove text <code>HTTP_services.cgi?FILENAME=%2Fdata%2FGPM_L3%2FGPM_3IMERGM.06%2F2000%2F3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5&amp;FORMAT=bmM0Lw&amp;BBOX=-8.8,105.05,-5.05,116.25&amp;LABEL=</code> and leaving <code>3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5.nc4</code>).  Using <code>rename</code> command, make sure you are navigate to <code>IMERG_mmhr</code> directory in your terminal, type below code: </p> </li> </ul> <pre><code>rename 's/.{178}//g' *.nc4`\n</code></pre> <p></p> <p>And below is the result!</p> <p></p>"},{"location":"imergnc/#convert-unit-from-mmhr-to-mmmonth","title":"Convert unit from mm/hr to mm/month","text":"<p>Make sure you are inside <code>gis</code> environment and <code>IMERG_mmhr</code> folder, I will use NCO to pre-process the data. </p> <ul> <li>Let's read header contents of a netCDF file in <code>IMERG_mmhr</code> folder. I will use this data <code>3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5.nc4</code> as example. Type and execute below code:</li> </ul> <pre><code>ncdump -h 3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5.nc4\n</code></pre> <p>You will get information (dimension, variables and global attribute) about the data.</p> <p></p> <p>As you can see above picture, the original downloaded files unit from GPM IMERG is in <code>mm/hr</code>, while to calculate monthly SPI, the data must be in <code>mm/month</code>. I need to do a conversion process using <code>ncap2</code> (arithmatic operator for netCDF files) command by multiplying number of day in month with <code>24hour</code>. Example:</p> <ul> <li>Rainfall value in Month: <code>JAN</code>, <code>MAR</code>, <code>MAY</code>, <code>JUL</code>, <code>AUG</code>, <code>OCT</code>, <code>DEC</code> which has <code>31</code> days will multiply with <code>744</code> to get <code>mm/month</code></li> <li>Rainfall value in Month: <code>APR</code>, <code>JUN</code>, <code>SEP</code>, <code>NOV</code> which has <code>30</code> days will multiply with <code>720</code> to get <code>mm/month</code></li> <li>Rainfall value in Month: <code>FEB</code> in a leap year which has 29 days will multiply with <code>696</code> to get <code>mm/month</code></li> <li>Rainfall value in Month: <code>FEB</code> in a normal year which has 28 days will multiply with <code>672</code> to get <code>mm/month</code></li> </ul> <p>To do the calculation, I will use below script to help generate line of codes for converting value of each data from <code>mm/hr</code> to <code>mm/month</code></p> <pre><code>while read -r _file; do\nfile=$(basename -- \"$_file\")\nyearmonth=$(echo \"$file\" | sed -E 's/.*\\.3IMERG\\.([0-9]{6})[0-9]{2}-.*/\\1/')\nmult=$(python - \"$yearmonth\" &lt;&lt;EOF\nimport sys, calendar\nym = sys.argv[1]\nprint(calendar.monthrange(int(ym[:4]), int(ym[4:]))[1] * 24)\nEOF\n);\necho ncap2 -s 'precipitation='\"$mult\"'*precipitation' \"$file\" ../IMERG_mmmonth/\"$file\";\ndone &lt; &lt;(find . -maxdepth 1 -type f -name \"*.nc4\") &gt; script.sh\n</code></pre> <p>Paste above code in your Terminal and Enter. You will get a file named <code>script.sh</code> as the result.</p> <p></p> <p>Then execute below</p> <pre><code>sh script.sh\n</code></pre> <p></p> <p>All file inside <code>IMERG_mmmonth</code> will have rainfall which show the value in <code>mm/month</code>. Let's check file <code>3B-MO.MS.MRG.3IMERG.20000601-S000000-E235959.06.V06B.HDF5.nc4</code> in folder <code>IMERG_mmhr</code> and <code>IMERG_mmmonth</code> using Panoply, see the difference in range of value.</p> <ul> <li> <p>Monthly rainfall in <code>mm/hr</code></p> <p></p> </li> <li> <p>Monthly rainfall in <code>mm/month</code></p> <p></p> </li> </ul> <p>I am aware the unit text still in <code>mm/hr</code>, I will explain how to edit it in the next topic.</p>"},{"location":"imergnc/#create-single-netcdf-file","title":"Create single netCDF file","text":"<p>Navigate to <code>IMERG_mmmonth</code> folder in Terminal. Loop all files in the folder <code>IMERG_mmmonth</code> to make <code>time</code> the record dimension/variable used for concatenating files using <code>ncks</code> command</p> <pre><code>for fl in *.nc4; do ncks -O --mk_rec_dmn time $fl $fl; done\n</code></pre> <p></p> <p>Concatenates all <code>nc4</code> files in <code>IMERG_mmmonth</code> folder into one <code>nc4</code> file named <code>IMERG_concat.nc4</code> using <code>ncrcat</code> command</p> <pre><code>ncrcat -h *.nc4 IMERG_concat.nc4\n</code></pre> <p></p> <p>Check the header</p> <pre><code>ncdump -h IMERG_concat.nc4\n</code></pre> <p></p> <p>And the variables for precipitation is <code>time</code>,<code>lon</code>,<code>lat</code> but SPI calculation required:</p> <ul> <li><code>lat</code>,<code>lon</code>,<code>time</code> or</li> <li><code>time</code>,<code>lat</code>,<code>lon</code></li> </ul> <p>Let's re-order the variables into <code>time</code>,<code>lat</code>,<code>lon</code> using <code>ncpdq</code> command, to be able running the SPI code in Python</p> <pre><code>ncpdq -a time,lat,lon IMERG_concat.nc4 IMERG_concat_ncpdq0.nc4\n</code></pre> <p></p> <p>Check again the header for the result <code>IMERG_concat_ncpdq0.nc4</code></p> <pre><code>ncdump -h IMERG_concat_ncpdq0.nc4\n</code></pre> <p></p> <p>And the variables for precipitation is <code>time</code>,<code>lat</code>,<code>lon</code>, it means the result is correct. But the unit still in <code>mm/hr</code>.</p> <p>Warning</p> <p>Notes on re-ordering process (Case by case)</p> <p>After re-ordering the variables, sometimes user experience <code>lat</code> or <code>lon</code> dimension becomes <code>UNLIMITED</code> which is wrong. The <code>time</code> dimension should be the <code>UNLIMITED</code> dimension.</p> <p></p> <p>Fortunately you can do this to fix the <code>lat</code> or <code>lon</code> dimension who becomes <code>UNLIMITED</code> using <code>ncks</code> command below:</p> <pre><code>ncks --fix_rec_dmn lat IMERG_concat_ncpdq0.nc4 -o outfixed.nc4 ; mv outfixed.nc4 IMERG_concat_ncpdq0.nc4\n</code></pre> <p>And to make <code>UNLIMITED</code> the <code>time</code> dimension again using <code>ncks</code> command below:</p> <pre><code>ncks --mk_rec_dmn time IMERG_concat_ncpdq0.nc4 -o outunlim.nc4 ; mv outunlim.nc4 IMERG_concat_ncpdq0.nc4\n</code></pre> <p>If you don't come accross the problem, <code>lat</code> or <code>lon</code> dimension becomes <code>UNLIMITED</code>, then skip above process and go directly to step below.</p> <p>SPI code does not recognized unit <code>mm/hr</code> or <code>mm/month</code>, I need to edit into <code>mm</code>. To edit the unit attribute names, I will use <code>ncatted</code> command, follow below code.</p> <pre><code>ncatted -a units,precipitation,modify,c,'mm' IMERG_concat_ncpdq0.nc4 IMERG_concat_ncpdq1.nc4\n</code></pre> <p></p> <p>Check again the header for <code>IMERG_concat_ncpdq1.nc4</code>, to make sure everything is correct.</p> <pre><code>ncdump -h IMERG_concat_ncpdq1.nc4\n</code></pre> <p></p> <p>And the units already in <code>mm</code></p> <p>Once this has completed, the dataset can be used as input to this package for computing SPI. From above picture, some of the precipitation attribute are still wrong: <code>DimensionNames</code> and <code>Units</code>. I can leave it as is, SPI code will only read <code>units</code> and variables <code>precipitation(time,lat,lon)</code></p> <p>As the input data preparation is completed, move the file <code>IMERG_concat_ncpdq1.nc4</code> to main folder <code>Input_nc</code> and rename into <code>java_cli_imerg_1months_2000_2020.nc</code></p> <pre><code>mv IMERG_concat_ncpdq1.nc4 ../../../Input_nc/java_cli_imerg_1months_2000_2020.nc\n</code></pre> <p></p> <p>Make sure the file <code>java_cli_imerg_1months_2000_2020.nc</code> is available at <code>Input_nc</code> folder</p> <p></p>"},{"location":"output/","title":"Example output","text":"<p>Below is the example of SPI calculation using IMERG and CHIRPS data,</p> <p>SPI 3-month, March 2020.</p>"},{"location":"output/#imerg","title":"IMERG","text":""},{"location":"output/#chirps","title":"CHIRPS","text":"<p>And comparison with SPI generated by:</p>"},{"location":"output/#bmkg","title":"BMKG","text":"<p>Indonesia Meteorological, Climatological and Geophysical Agency (BMKG) regularly produce SPI-3 and published on their website every month https://www.bmkg.go.id/iklim/indeks-presipitasi-terstandarisasi.bmkg</p> <p>Link for SPI 3-month, March 2020 - https://www.bmkg.go.id/iklim/indeks-presipitasi-terstandarisasi.bmkg?p=the-standardized-precipitation-index-maret-2020&amp;tag=spi&amp;lang=ID</p> <p></p>"},{"location":"output/#climate-engine","title":"Climate Engine","text":"<p>Climate Engine is a free web application powered by Google Earth Engine that can be used to create on-demand maps and charts from publicly available satellite and climate data using a standard web browser. Climate Engine allows users to analyze and interact with climate and earth observations for decision support related to drought, water use, agricultural, wildfire, and ecology.</p> <p>One of the product that could generate easily using Climate Engine is SPI. Link https://climengine.page.link/nTyi</p> <p></p>"},{"location":"pyenv/","title":"2. Configure the python environment","text":"<p>The code for calculating SPI is written in Python 3. It is recommended to use either the Miniconda3 (minimal Anaconda) or Anaconda3 distribution. The below instructions will be Anaconda specific (although relevant to any Python virtual environment), and assume the use of a bash shell.</p> <p>A new Anaconda environment can be created using the conda environment management system that comes packaged with Anaconda. In the following examples, I\u2019ll use an environment named <code>climate_indices</code> (any environment name can be used instead of <code>climate_indices</code>) which will be created and populated with all required dependencies through the use of the provided setup.py file.</p> <p>Note</p> <p>This step must only be done the first time. Once the environment has been created there is no need to do it again.</p> <ul> <li>First, open your Terminal (in your macOS/Linux and Ubuntu Linux on WSL), create the Python environment with <code>python3.7</code> as default:</li> </ul> <pre><code>conda create -n climate_indices python=3.7\n</code></pre> <p></p> <p>Proceed with <code>y</code></p> <ul> <li>The environment created can now be \u2018activated\u2019:</li> </ul> <pre><code>conda activate climate_indices\n</code></pre> <ul> <li>Install climate-indices package. Once the environment has been activated then subsequent Python commands will run in this environment where the package dependencies for this project are present. Now the package can be added to the environment along with all required modules (dependencies) via pip:</li> </ul> <pre><code>pip install climate-indices\n</code></pre> <p></p> <ul> <li>Install netCDF Operator (NCO) using <code>conda</code> and proceed with <code>y</code>.</li> </ul> <pre><code>conda install -c conda-forge nco\n</code></pre> <ul> <li>Install Climate Data Operator (CDO) from Max-Planck-Institut f\u00fcr Meteorologie using <code>conda</code> and proceed with <code>y</code>.</li> </ul> <pre><code>conda install -c conda-forge cdo\n</code></pre> <ul> <li>Install <code>jupyter</code> and other package using <code>conda</code> and proceed with <code>y</code>.</li> </ul> <pre><code>conda install -c conda-forge jupyter numpy netCDF4\n</code></pre> <ul> <li>Deactivate an active environment <code>climate_indices</code> as  I will create a new environment called <code>gis</code> to install <code>gdal</code> to clip the rainfall data using a shapefile, and proceed with <code>y</code>.</li> </ul> <pre><code>conda deactivate &amp;&amp; conda create -n gis python=3.7\n</code></pre> <p></p> <ul> <li>The environment created can now be \u2018activated\u2019:</li> </ul> <pre><code>conda activate gis\n</code></pre> <ul> <li>Install <code>gdal</code>, <code>nco</code> and <code>cdo</code> in <code>gis</code> environment and proceed with <code>y</code>.</li> </ul> <pre><code>conda install -c conda-forge gdal nco cdo wget\n</code></pre> <p></p>"},{"location":"rainfall/","title":"3. Preparing input for SPI","text":"<p>SPI requires monthly rainfall data, and there are many source providing global high-resolution gridded monthly rainfall data:</p> <ul> <li>CHIRPS</li> <li>IMERG</li> <li>FLDAS</li> <li>TerraClimate</li> <li>CRU</li> </ul> <p>For better result, SPI required minimum 30-years of data.</p> <p>I provide 3 different approach to prepare rainfall data ready to use as SPI input. For learning matters, you may follow all the approach. Or you can choose which one is suit for you depend on the data source and format:</p> <ul> <li>IMERG monthly in netCDF</li> <li>CHIRPS monthly in GeoTIFF</li> <li>CHIRPS monthly in netCDF</li> </ul> <p>Why I chosed CHIRPS as an alternative example from IMERG? It is produced at 0.05 x 0.05 degree spatial resolution, make CHIRPS the highest gridded rainfall data, and long-term historical data from 1981 \u2013 now.</p> <p>If you are prefer to use your own dataset also fine, you can still follow this guideline and adjust some steps and code related to filename, unit, format and structure.</p>"},{"location":"rainfall/#input-specification","title":"Input specification","text":"<p>The climate-indices python package enables the user to calculate SPI using any gridded netCDF dataset. However, there are certain specifications for input files that vary based on input type.</p> <ul> <li> <p>Precipitation unit must be written as <code>millimeters</code>, <code>milimeter</code>, <code>mm</code>, <code>inches</code>, <code>inch</code> or <code>in</code>.</p> </li> <li> <p>Data dimension and order must be written as <code>lat</code>, <code>lon</code>, <code>time</code> (Windows machine required this order) or <code>time</code>, <code>lat</code>, <code>lon</code> (Works tested on Mac/Linux and Linux running on WSL).</p> </li> </ul>"},{"location":"references/","title":"References","text":""},{"location":"references/#journal","title":"Journal","text":"<ul> <li>Guttman, N. B., 1999: Accepting the Standardized Precipitation Index: A calculation algorithm. J. Amer. Water Resour. Assoc., 35(2), 311-322. Link</li> <li>Lloyd Hughes, B., and M. A. Saunders, 2002: A drought climatology for Europe. Int. J. Climatol., DOI:10.1002/joc.846 Link</li> <li>McKee, T.B., N. J. Doesken, and J. Kliest, 1993: The relationship of drought frequency and duration to time scales. In Proceedings of the 8th Conference of Applied Climatology, 17 22 January, Anaheim, CA. American Meterological Society, Boston, MA. 179-18. Link</li> <li>Guttman, N. B., 1998: Comparing the Palmer Drought Index and the Standardized Precipitation Index. J. Amer. Water Resources Assoc., 34(1), 113-121. </li> <li>Edwards, D. C., and T. B. McKee, 1997: Characteristics of 20th century drought in the United States at multiple time scales. Climatology Report No. 97-2, Colorado State Univ., Ft. Collins, CO. </li> <li>McKee, T. B., N. J. Doesken, and J. Kleist, 1995: Drought monitoring with multiple time scales. Ninth Conference on Applied Climatology, American Meteorological Society, Jan15-20, 1995, Dallas TX, pp.233-236.</li> </ul>"},{"location":"references/#website","title":"Website","text":"<ul> <li>Keyantash, John &amp; National Center for Atmospheric Research Staff (Eds). \"The Climate Data Guide: Standardized Precipitation Index (SPI).\" Retrieved from https://climatedataguide.ucar.edu/climate-data/standardized-precipitation-index-spi</li> <li>National Drought Mitigation Center (NDMC) at the University of Nebraska Lincoln. Link</li> <li>World Meteorological Organization (WMO), 2012: Standardized Precipitation Index User Guide. Link</li> <li>Climate Indices in Python https://climate-indices.readthedocs.io/en/latest/</li> <li>Climate Engine - https://app.climateengine.org/climateEngine</li> <li>BMKG - https://www.bmkg.go.id/iklim/indeks-presipitasi-terstandarisasi.bmkg</li> <li>NASA ARSET on Application of GPM IMERG Reanalysis for Assessing Extreme Dry and Wet Periods. Link</li> <li>Climate Data Operator - https://code.mpimet.mpg.de/projects/cdo</li> <li>netCDF Operator - http://nco.sourceforge.net</li> <li>CHIRPS, Climate Hazard Centre UCSB - https://chc.ucsb.edu/data/chirps</li> <li>IMERG, Integrated Multi-satellitE Retrievals for GPM - https://gpm.nasa.gov/data/imerg</li> <li>https://benny.istan.to/blog/20200706-calculate-spi-using-imerg-data</li> <li>https://benny.istan.to/blog/20200710-calculate-spi-using-chirps-data</li> <li>https://benny.istan.to/blog/20201210-geotiff-to-netcdf-file-with-time-dimension-enabled-and-cf-compliant</li> <li>https://benny.istan.to/blog/20210125-calculate-spi-using-monthly-rainfall-data-in-geotiff-format</li> </ul>"},{"location":"software/","title":"1. Software Requirement","text":"<p>If you encounter a problem, please look for a online solution. The installation and configuration described below is mostly performed using a bash shell on macOS. Windows users will need to install and configure a bash shell in order to follow the usage shown below. Try to use Windows Subsystem for Linux for this purpose.</p>"},{"location":"software/#macoslinux","title":"macOS/Linux","text":""},{"location":"software/#installing-software-for-macoslinux","title":"Installing software for macOS/Linux","text":"<p>If you are new to using Bash refer to the following lessons with Software Carpentry: http://swcarpentry.github.io/shell-novice/</p> <ul> <li>If you don't have Homebrew, you can install it by pasting below code in your macOS/Linux terminal.</li> </ul> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <ul> <li>Install <code>wget</code> (for downloading data). Use Hombrew to install it by pasting below code in your macOS terminal.</li> </ul> <pre><code>brew install wget\n</code></pre> <ul> <li> <p>Download and install Panoply Data Viewer from NASA GISS on your machine for macOS or Linux.</p> </li> <li> <p>Download and install Anaconda Python on your machine for macOS or Linux.</p> <ul> <li>Follow Installing Anaconda on macOS guideline and for Linux</li> </ul> <p>Tip</p> <p>Or you can use Miniconda for macOS or Linux. And follow the installation guideline for macOS and Linux</p> </li> </ul>"},{"location":"software/#windows","title":"Windows","text":""},{"location":"software/#enable-the-windows-subsytem-for-linux","title":"Enable the Windows Subsytem for Linux","text":"<p>Note</p> <p>If you are using Windows machine, it's recomended to follow below step. You will experience an error during SPI calculation cause by <code>NCO</code> if you use standard Windows 10 and not using Windows Subsytem for Linux. </p> <p>Guideline below are specific for Windows 10. If you are using Windows Server 2019, please follow Windows Server Installation Guide</p> <p>Reference: https://docs.microsoft.com/en-us/windows/wsl/install-win10</p> <p>You must first enable the \"Windows Subsystem for Linux - WSL\" optional feature before installing any Linux distributions on Windows.</p> <p>Open PowerShell as Administrator (right-click PowerShell) and run:</p> <pre><code>dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n</code></pre>"},{"location":"software/#update-to-wsl-2","title":"Update to WSL 2","text":"<p>Check requirements for running WSL 2</p> <p>To update to WSL 2, you must be running Windows 10.</p> <ul> <li>For x64 systems: Version 1903 or higher, with Build 18362 or higher.</li> <li>For ARM64 systems: Version 2004 or higher, with Build 19041 or higher.</li> </ul> <p>Builds lower than 18362 do not support WSL 2. Use the Windows Update Assistant to update your version of Windows.</p> <p>To check your version and build number, select Windows logo key + R, type winver, select OK. Update to the latest Windows version in the Settings menu.</p> <p>Note</p> <p>If you are running Windows 10 version 1903 or 1909, open \"Settings\" from your Windows menu, navigate to \"Update &amp; Security\" and select \"Check for Updates\". Your Build number must be 18362.1049+ or 18363.1049+, with the minor build # over .1049. Read more: WSL 2 Support is coming to Windows 10 Versions 1903 and 1909. See the troubleshooting instructions.</p>"},{"location":"software/#enable-virtual-machine-feature","title":"Enable Virtual Machine feature","text":"<p>Before installing WSL 2, you must enable the Virtual Machine Platform optional feature. Your machine will require virtualization capabilities to use this feature.</p> <p>Open PowerShell as Administrator (right-click PowerShell) and run:</p> <pre><code>dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n</code></pre> <p>Restart your machine to complete the WSL install and update to WSL 2.</p>"},{"location":"software/#download-the-linux-kernel-update-package","title":"Download the Linux kernel update package","text":"<p>Download the latest package:</p> <ul> <li> <p>WSL2 Linux kernel update package for x64 machines</p> <p>Note</p> <p>If you're using an ARM64 machine, please download the ARM64 package instead. If you're not sure what kind of machine you have, open Command Prompt or PowerShell and enter: <code>systeminfo | find \"System Type\"</code>. Caveat: On non-English Windows versions, you might have to modify the search text, for example, in German it would be <code>systeminfo | find \"Systemtyp\"</code>.</p> </li> <li> <p>Run the update package downloaded in the previous step. (Double-click to run - you will be prompted for elevated permissions, select \u2018yes\u2019 to approve this installation.)</p> </li> </ul> <p>Once the installation is complete, move on to the next step - setting WSL 2 as your default version when installing new Linux distributions. (Skip this step if you want your new Linux installs to be set to WSL 1).</p> <p>Note</p> <p>For more information, read the article changes to updating the WSL2 Linux kernel, available on the Windows Command Line Blog.</p>"},{"location":"software/#set-wsl-2-as-your-default-version","title":"Set WSL 2 as your default version","text":"<p>Open PowerShell and run this command to set WSL 2 as the default version when installing a new Linux distribution:</p> <pre><code>wsl --set-default-version 2\n</code></pre>"},{"location":"software/#install-your-linux-distribution-of-choice","title":"Install your Linux distribution of choice","text":"<ul> <li> <p>Open the Microsoft Store and select your favourite Linux distribution.</p> <p></p> <p>Let's focus to use Ubunto 20.04 LTS distro</p> </li> <li> <p>From the distribution's page, select \"Get\"</p> <p></p> </li> </ul> <p>The first time you launch a newly installed Linux distribution, a console window will open and you'll be asked to wait for a minute or two for files to de-compress and be stored on your PC. All future launches should take less than a second.</p> <p>You will then need to create a user account and password for your new Linux distribution.</p> <p></p> <p>CONGRATULATIONS! You've successfully installed and set up a Linux distribution that is completely integrated with your Windows operating system!</p>"},{"location":"software/#install-windows-terminal-optional","title":"Install Windows Terminal (optional)","text":"<p>Windows Terminal enables multiple tabs (quickly switch between multiple Linux command lines, Windows Command Prompt, PowerShell, Azure CLI, etc), create custom key bindings (shortcut keys for opening or closing tabs, copy+paste, etc.), use the search feature, and custom themes (color schemes, font styles and sizes, background image/blur/transparency). Learn more.</p> <p>Install Windows Terminal.</p> <p></p>"},{"location":"software/#set-your-distribution-version-to-wsl-1-or-wsl-2","title":"Set your distribution version to WSL 1 or WSL 2","text":"<p>You can check the WSL version assigned to each of the Linux distributions you have installed by opening the PowerShell command line and entering the command (only available in Windows Build 18362 or higher): <code>wsl -l -v</code></p> <p><pre><code>wsl --list --verbose\n</code></pre> To set a distribution to be backed by either version of WSL please run:</p> <pre><code>wsl --set-version &lt;distribution name&gt; &lt;versionNumber&gt;\n</code></pre> <p>Make sure to replace <code>&lt;distribution name&gt;</code> with the actual name of your distribution and <code>&lt;versionNumber&gt;</code> with the number '1' or '2'. You can change back to WSL 1 at anytime by running the same command as above but replacing the '2' with a '1'.</p> <p>Note</p> <p>The update from WSL 1 to WSL 2 may take several minutes to complete depending on the size of your targeted distribution. If you are running an older (legacy) installation of WSL 1 from Windows 10 Anniversary Update or Creators Update, you may encounter an update error. Follow these instructions to uninstall and remove any legacy distributions.</p> <p>If <code>wsl --set-default-version</code> results as an invalid command, enter <code>wsl --help</code>. If the <code>--set-default-version</code> is not listed, it means that your OS doesn't support it and you need to update to version 1903, Build 18362 or higher. If you are on Build 19041 for ARM64, this command may fail when using PowerShell in which case you can use a Command Prompt instead to issue the <code>wsl.exe</code> command.</p> <p>If you see this message after running the command: <code>WSL 2 requires an update to its kernel component. For information please visit https://aka.ms/wsl2kernel</code>. You still need to install the MSI Linux kernel update package.</p> <p>Additionally, if you want to make WSL 2 your default architecture you can do so with this command:</p> <pre><code>wsl --set-default-version 2\n</code></pre> <p>This will set the version of any new distribution installed to WSL 2.</p>"},{"location":"software/#installing-software-for-windows","title":"Installing software for Windows","text":"<p>If you have a Bash shell already installed on your Windows OS (e.g. Ubuntu Bash) you can use that for the exercise, but it must be a Bash shell</p> <p>If you are new to using Bash refer to the following lessons with Software Carpentry: http://swcarpentry.github.io/shell-novice/</p> <ul> <li>If you don't have Homebrew, you can install it by pasting below code in your WSL Ubuntu terminal.</li> </ul> <pre><code>bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n</code></pre> <ul> <li>Install <code>wget</code> (for downloading data). Use Hombrew to install it by pasting below code in your WSL Ubuntu  terminal.</li> </ul> <pre><code>brew install wget\n</code></pre> <ul> <li> <p>Download and install Panoply Data Viewer from NASA GISS on your machine: Windows.</p> </li> <li> <p>Download and install Anaconda Python on your WSL Ubuntu Linux. : Ubuntu Linux on WSL.</p> </li> </ul> <p>Warning</p> <p><code>climate-indices</code> python package used for SPI calculation is rely on netCDF Operator (NCO) and pyNCO wrapper sometimes produce an error in Windows. That's the reason why we will use Anaconda for Linux if you are using Windows machine.</p> <p>Reference: https://gist.github.com/kauffmanes/5e74916617f9993bc3479f401dfec7da</p> <ul> <li>Go to https://repo.anaconda.com/archive/ to find the list of Anaconda releases</li> <li>Select the release you want. I have a 64-bit computer, so I chose the latest release ending in <code>x86_64.sh</code>. If I had a 32-bit computer, I'd select the <code>x86.sh</code> version. If you accidentally try to install the wrong one, you'll get a warning in the terminal. I chose <code>Anaconda3-2020.11-Linux-x86_64.sh</code>.</li> <li>From the terminal run <code>wget https://repo.anaconda.com/archive/[YOUR VERSION]</code>. Example: </li> </ul> <pre><code>wget https://repo.anaconda.com/archive/Anaconda3-2020.11-Linux-x86_64.sh\n</code></pre> <p></p> <ul> <li>After download process completed, Run the installation script: <code>bash Anaconda[YOUR VERSION].sh</code> </li> </ul> <pre><code>bash Anaconda3-2020.11-Linux-x86_64.sh\n</code></pre> <ul> <li>Read the license agreement and follow the prompts to press Return/Enter to accept. Later will follow with question on accept the license terms, type <code>yes</code> and Enter. When asks you if you'd like the installer to prepend it to the path, press Return/Enter to confirm the location. Last question will be about initialize Anaconda3, type <code>yes</code> then Enter.</li> <li>Close the terminal and reopen it to reload .bash configs. It will automatically activate <code>base</code> environment.</li> <li>Deactivate <code>base</code> environment then set to <code>false</code> the confirguration of auto activate the <code>base</code> environment by typing</li> </ul> <pre><code>conda deactivate &amp;&amp; conda config --set auto_activate_base false\n</code></pre> <ul> <li> <p>To test that it worked, <code>which python</code> in your Terminal. It should print a path that has anaconda in it. Mine is <code>/home/bennyistanto/anaconda3/bin/python</code>. If it doesn't have anaconda in the path, do the next step.</p> <p></p> </li> <li> <p>Manually add the Anaconda bin folder to your PATH. To do this, I added <code>\"export PATH=/home/bennyistanto/anaconda3/bin:$PATH\"</code> to the bottom of my <code>~/.bashrc</code> file.</p> </li> <li> <p>Optionally install Visual Studio Code when prompted</p> <p>Info</p> <p>Or you can use Miniconda: Ubuntu Linux on WSL.</p> </li> </ul>"},{"location":"spi/","title":"4. Calculate SPI","text":"<p>Let's start the calculation!</p> <ul> <li>Deactivate an active environment <code>gis</code> then activate environment <code>climate_indices</code> to start working on SPI calculation.</li> </ul> <pre><code>conda deactivate &amp;&amp; conda activate climate_indices\n</code></pre> <p>Note</p> <p>Please make sure the input file are following input requirements for SPI</p> <ul> <li>Variable name on precipitation <code>--var_name_precip</code>, usually IMERG data use <code>precipitation</code> as name while CHIRPS using <code>precip</code>. To make sure, check using command <code>ncdump -h file.nc</code> then adjust it in SPI script if needed.</li> <li>Precipitation unit must be written as <code>millimeters</code>, <code>milimeter</code>, <code>mm</code>, <code>inches</code>, <code>inch</code> or <code>in</code>.</li> <li>Data dimension and order must be written as <code>lat</code>, <code>lon</code>, <code>time</code> (Windows machine required this order) or <code>time</code>, <code>lat</code>, <code>lon</code> (Works tested on Mac/Linux and Linux running on WSL).</li> </ul>"},{"location":"spi/#imerg-data","title":"IMERG data","text":"<ul> <li> <p>Navigate your Terminal to folder <code>Input_nc</code></p> </li> <li> <p>In order to pre-compute fitting parameters for later use as inputs to subsequent SPI calculations, I can save both gamma and Pearson distribution fitting parameters to NetCDF, and later use this file as input for SPI calculations over the same calibration period.</p> <p>Make sure you check below information:</p> <ul> <li>Input file <code>java_cli_imerg_1months_2000_2020.nc</code> available at <code>Input_nc</code> folder. Example: <code>/Users/bennyistanto/Temp/IMERG/Java/Input_nc/</code> </li> <li>Output folder named <code>Output_nc</code> to save SPI result is exist in your working directory</li> <li>Output folder named <code>Fitting</code> to store fitting result is exist in your working directory</li> <li>Variable name is <code>precipitation</code></li> </ul> </li> </ul> <p>In your Terminal, run the following code.</p> <pre><code>spi --periodicity monthly --scales 1 2 3 6 9 12 24 36 48 60 72 --calibration_start_year 2000 --calibration_end_year 2020 --netcdf_precip /Users/bennyistanto/Temp/IMERG/SPI/Java/Input_nc/java_cli_imerg_1months_2000_2020.nc --var_name_precip precipitation --output_file_base /Users/bennyistanto/Temp/IMERG/SPI/Java/Output_nc/java_IMERG --multiprocessing all --save_params /Users/bennyistanto/Temp/IMERG/SPI/Java/Fitting/java_IMERG_fitting.nc --overwrite\n</code></pre> <p>Tip</p> <p>Above code is example for calculating SPI 1 to 72-months. It's ok if you think you only need some of them. Example: you are interested to calculate SPI 1 - 3-months, then adjust above code into <code>--scales 1 2 3</code> </p> <p></p> <p>The above command will compute SPI (standardized precipitation index, both gamma and Pearson Type III distributions) from an input precipitation dataset (in this case, IMERG precipitation dataset). The input dataset is monthly rainfall accumulation data and the calibration period used will be Jun-2000 through Dec-2020. The index will be computed at <code>1</code>,<code>2</code>,<code>3</code>,<code>6</code>,<code>9</code>,<code>12</code>,<code>24</code>,<code>36</code>,<code>48</code>,<code>60</code> and <code>72-month</code> timescales. The output files will be &lt;<code>out_dir&gt;/java_IMERG_spi_gamma_xx.nc</code>, and <code>&lt;out_dir&gt;/java_IMERG_spi_pearson_xx.nc</code>.</p> <p>The output files will be:</p> <p>Gamma</p> <ol> <li>1-month: <code>/Output_nc/java_IMERG_spi_gamma_01.nc</code></li> <li>2-month: <code>/Output_nc/java_IMERG_spi_gamma_02.nc</code></li> <li>3-month: <code>/Output_nc/java_IMERG_spi_gamma_03.nc</code></li> <li>6-month: <code>/Output_nc/java_IMERG_spi_gamma_06.nc</code></li> <li>9-month: <code>/Output_nc/java_IMERG_spi_gamma_09.nc</code></li> <li>12-month: <code>/Output_nc/java_IMERG_spi_gamma_12.nc</code></li> <li>24-month: <code>/Output_nc/java_IMERG_spi_gamma_24.nc</code></li> <li>36-month: <code>/Output_nc/java_IMERG_spi_gamma_36.nc</code></li> <li>48-month: <code>/Output_nc/java_IMERG_spi_gamma_48.nc</code></li> <li>60-month: <code>/Output_nc/java_IMERG_spi_gamma_60.nc</code></li> <li>72-month: <code>/Output_nc/java_IMERG_spi_gamma_72.nc</code></li> </ol> <p>Pearson</p> <ol> <li>1-month: <code>/Output_nc/java_IMERG_spi_pearson_01.nc</code></li> <li>2-month: <code>/Output_nc/java_IMERG_spi_pearson_02.nc</code></li> <li>3-month: <code>/Output_nc/java_IMERG_spi_pearson_03.nc</code></li> <li>6-month: <code>/Output_nc/java_IMERG_spi_pearson_06.nc</code></li> <li>9-month: <code>/Output_nc/java_IMERG_spi_pearson_09.nc</code></li> <li>12-month: <code>/Output_nc/java_IMERG_spi_pearson_12.nc</code></li> <li>24-month: <code>/Output_nc/java_IMERG_spi_pearson_24.nc</code></li> <li>36-month: <code>/Output_nc/java_IMERG_spi_pearson_36.nc</code></li> <li>48-month: <code>/Output_nc/java_IMERG_spi_pearson_48.nc</code></li> <li>60-month: <code>/Output_nc/java_IMERG_spi_pearson_60.nc</code></li> <li>72-month: <code>/Output_nc/java_IMERG_spi_pearson_72.nc</code></li> </ol> <p>Parallelization will occur utilizing all CPUs.</p>"},{"location":"spi/#chirps-data","title":"CHIRPS data","text":"<ul> <li>To make sure everything is correct and following above specifications, in your Terminal - navigate to your directory where you save <code>java_cli_chirps_1months_1981_2020.nc</code> file: <code>Input_nc</code>. Then type</li> </ul> <pre><code>ncdump -h java_cli_chirps_1months_1981_2020.nc\n</code></pre> <p>From above picture, I can say:</p> <ul> <li> Time dimension is enabled, <code>480</code> is total months from Jan 1981 to Dec 2020</li> <li> Data dimension and order are following the specification <code>time</code>, <code>lat</code>, <code>lon</code></li> <li> The unit is in <code>mm</code></li> </ul> <p>So, everything is correct and I am ready to calculate SPI. Make sure in your Terminal still inside <code>climate_indices</code> environment.</p> <p>Other requirements and options related to the indices calculation, please follow https://climate-indices.readthedocs.io/en/latest/#indices-processing</p> <ul> <li> <p>In order to pre-compute fitting parameters for later use as inputs to subsequent SPI calculations I can save both gamma and Pearson distribution fitting parameters to NetCDF, and later use this file as input for SPI calculations over the same calibration period.</p> <p>Make sure you check below information:</p> <ul> <li>Input file <code>java_cli_chirps_1months_1981_2021.nc</code> available at <code>Input_nc</code> folder. Example: <code>/Users/bennyistanto/Temp/CHIRPS/Java/Input_nc/</code> </li> <li>Output folder named <code>Output_nc</code> to save SPI result is exist in your working directory</li> <li>Output folder named <code>Fitting</code> to store fitting result is exist in your working directory</li> <li>Variable name is <code>precip</code></li> </ul> </li> </ul> <p>In your Terminal, run the following code.</p> <pre><code>spi --periodicity monthly --scales 1 2 3 6 9 12 24 36 48 60 72 --calibration_start_year 1981 --calibration_end_year 2020 --netcdf_precip /Users/bennyistanto/Temp/CHIRPS/SPI/Java/Input_nc/java_cli_chirps_1months_1981_2021.nc --var_name_precip precip --output_file_base /Users/bennyistanto/Temp/CHIRPS/SPI/Java/Output_nc/java_CHIRPS --multiprocessing all --save_params /Users/bennyistanto/Temp/CHIRPS/SPI/Java/Fitting/java_CHIRPS_fitting.nc --overwrite\n</code></pre> <p>Tip</p> <p>Above code is example for calculating SPI 1 to 72-months. It's ok if you think you only need some of them. Example: you are interested to calculate SPI 1 - 3-months, then adjust above code into <code>--scales 1 2 3</code> </p> <p></p> <p>The above command will compute SPI (standardized precipitation index, both gamma and Pearson Type III distributions) from an input precipitation dataset (in this case, CHIRPS precipitation dataset). The input dataset is monthly rainfall accumulation data and the calibration period used will be Jan-1981 through Dec-2020. The index will be computed at <code>1</code>,<code>2</code>,<code>3</code>,<code>6</code>,<code>9</code>,<code>12</code>,<code>24</code>,<code>36</code>,<code>48</code>,<code>60</code> and <code>72-month</code> timescales. The output files will be &lt;<code>out_dir&gt;/java_CHIRPS_spi_gamma_xx.nc</code>, and <code>&lt;out_dir&gt;/java_CHIRPS_spi_pearson_xx.nc</code>.</p> <p>The output files will be:</p> <p>Gamma</p> <ol> <li>1-month: <code>/Output_nc/java_CHIRPS_spi_gamma_01.nc</code></li> <li>2-month: <code>/Output_nc/java_CHIRPS_spi_gamma_02.nc</code></li> <li>3-month: <code>/Output_nc/java_CHIRPS_spi_gamma_03.nc</code></li> <li>6-month: <code>/Output_nc/java_CHIRPS_spi_gamma_06.nc</code></li> <li>9-month: <code>/Output_nc/java_CHIRPS_spi_gamma_09.nc</code></li> <li>12-month: <code>/Output_nc/java_CHIRPS_spi_gamma_12.nc</code></li> <li>24-month: <code>/Output_nc/java_CHIRPS_spi_gamma_24.nc</code></li> <li>36-month: <code>/Output_nc/java_CHIRPS_spi_gamma_36.nc</code></li> <li>48-month: <code>/Output_nc/java_CHIRPS_spi_gamma_48.nc</code></li> <li>60-month: <code>/Output_nc/java_CHIRPS_spi_gamma_60.nc</code></li> <li>72-month: <code>/Output_nc/java_CHIRPS_spi_gamma_72.nc</code></li> </ol> <p>Pearson</p> <ol> <li>1-month: <code>/Output_nc/java_CHIRPS_spi_pearson_01.nc</code></li> <li>2-month: <code>/Output_nc/java_CHIRPS_spi_pearson_02.nc</code></li> <li>3-month: <code>/Output_nc/java_CHIRPS_spi_pearson_03.nc</code></li> <li>6-month: <code>/Output_nc/java_CHIRPS_spi_pearson_06.nc</code></li> <li>9-month: <code>/Output_nc/java_CHIRPS_spi_pearson_09.nc</code></li> <li>12-month: <code>/Output_nc/java_CHIRPS_spi_pearson_12.nc</code></li> <li>24-month: <code>/Output_nc/java_CHIRPS_spi_pearson_24.nc</code></li> <li>36-month: <code>/Output_nc/java_CHIRPS_spi_pearson_36.nc</code></li> <li>48-month: <code>/Output_nc/java_CHIRPS_spi_pearson_48.nc</code></li> <li>60-month: <code>/Output_nc/java_CHIRPS_spi_pearson_60.nc</code></li> <li>72-month: <code>/Output_nc/java_CHIRPS_spi_pearson_72.nc</code></li> </ol> <p>Parallelization will occur utilizing all CPUs.</p>"},{"location":"spi/#time-processing","title":"Time processing","text":"<p>For small area of interest, the calculation will fast and don\u2019t take much time. Below is one of example if you processed bigger area:</p> <ul> <li> <p>Monthly IMERG data, global coverage 180W - 180E, 60N - 60S, 0.1 deg spatial resolution. It takes almost 9-hours to process SPI 1-72 months.</p> <p></p> <p>Output gamma and pearson file https://github.com/bennyistanto/spi/blob/master/example/Data/Output_nc</p> <p>Fitting file https://github.com/bennyistanto/spi/blob/master/example/Data/Fitting</p> </li> </ul>"},{"location":"update/","title":"5. Updating procedure when new data is available","text":"<p>What if the new data is coming (Jan 2021)? Should I re-run again for the whole periods, 1981 to date? That's not practical as it requires large storage and time processing if you do for bigger coverage (country or regional analysis).</p> <p>So far, updating the SPI process is easy if I used CHIRPS in GeoTIFF format. Below are some reason:</p> <ul> <li> <p>Downloading new CHIRPS data in netCDF is painful, because I need to download whole package data (6.4 GB and start from Jan 1981 to date) eventhough I only need the latest month.</p> </li> <li> <p>CHIRPS data in GeoTIFF provides 1 month 1 GeoTIFF file, only take what you need!</p> </li> <li> <p>IMERG included data over the sea, and easiest way to clipped netCDF data is using bounding box. This approach will not have a problem if all of our area interest is in land.</p> </li> </ul> <p>Updating SPI up to SPI-72, I should have data at least 6 years back (2014) from the latest (Jan 2021). In order to avoid computation for the whole periods (1981-2021), I will process data data only for year 2014 to 2021.</p> <p>After that, I continue the process following Step 3 to do conversion process to netCDF format from bunch of GeoTIFF file in a folder with time dimension enabled.</p> <p>Step 4 demonstrates how distribution fitting parameters can be saved as NetCDF. This fittings NetCDF can then be used as pre-computed variables in subsequent SPI computations. Initial command computes both distribution fitting values and SPI for various month scales.</p> <p>The distribution fitting variables are written to the file specified by the <code>--save_params</code> option.</p> <p>The below command also computes SPI but instead of computing the distribution fitting values it loads the pre-computed fitting values from the NetCDF file specified by the <code>--load_params</code> option.</p> <p>See below code:</p> <pre><code>spi --periodicity monthly --scales 1 2 3 6 9 12 24 36 48 60 72 --calibration_start_year 1981 --calibration_end_year 2020 --netcdf_precip /Users/bennyistanto/Temp/CHIRPS/Java/Input_nc/java_cli_chirps_1months_2014_2021.nc --var_name_precip precip --output_file_base /Users/bennyistanto/Temp/CHIRPS/Java/Output_nc/java_CHIRPS --multiprocessing all --load_params /Users/bennyistanto/Temp/CHIRPS/Java/Fitting/java_CHIRPS_fitting.nc\n</code></pre> <p></p>"},{"location":"vizualisation/","title":"6. Visualize the result using Panoply","text":"<p>Let see the result.</p> <ul> <li> <p>From the <code>Output_nc</code> directory, right-click file <code>java_CHIRPS_spi_gamma_3_month.nc</code> and Open With Panoply.</p> <p>If you are not following the tutorial but interested to see the file, you can download this file from this link: https://on.istan.to/2MhVnTP </p> <p></p> </li> <li> <p>From the Datasets tab select spi_gamma_3_month and click Create Plot</p> <p></p> </li> <li> <p>In the Create Plot window select option Georeferenced Longitude-Latitude.</p> </li> <li> <p>When the Plot window opens:</p> <ul> <li>Array tab: Change the time into <code>469</code> to view data on <code>Jan 2020</code></li> <li>Scale tab: Change value on Min <code>-3</code>, Max <code>3</code>, Major <code>6</code>, Color Table <code>CB_RdBu_09.cpt</code></li> <li>Map tab: Change value on Center on Lon <code>110.0</code> Lat <code>-7.5</code>, then Zoom in the map through menu-editor Plot &gt; Zoom - Plot In few times until Indonesia appear proportionally. Set grid spacing <code>2.0</code> and Labels on every grid lines.</li> <li>Overlays tab: Change <code>Overlay 1</code> to <code>MWDB_Coasts_Countries_1.cnob</code></li> </ul> <p></p> </li> </ul>"}]}